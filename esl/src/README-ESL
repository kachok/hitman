------ DATABASE FILES -------

esl.sql - file to build all tables need to support esl HIT generation, data collection, and grading (NOT up to date)

------ SCRIPTS -------

add_esl_hits_to_mturk.py - add the HITs generated by generate_esl_hits.py to MTurk

approve_reject.py - read reviewed assignments from database (buffered in process_qc.py), approve/reject each assignment on MTurk, and roll buffered review data into the esl_workers database

buffer_update.py - take results out of buffer and read into relevant esl2 tables (should be run after running multi_test, since requires full buffer)

reloadall.sh - runs cleanup.py, cleardb.py, load_data_to_db.py in that order. recommended using instead of running individually, since it will avoid accidentally clearing DB before removing hits from mturk.

cleanup.py - expire all hits currently on mturk, make no longer available to workers

cleardb.py - clear all entries out of DB. clears all sentences, hits, assignments, hits_results, location data. does not clear esl_workers data or esl_edits data
 
data_dump.py - pull all data out of the DB and dumps into csv files. creates 7 files (assign_data, edit_data, hitdata_data, worker_data, cntrl_data, hit_data, sent_ids) corresponding to the esl2 tables assignments, esl_edits, esl_hits_data, esl_workers, esl_controls, hits, and esl_sents) 

generate_cntrlonly_hits.py - generate mturk hits consisting only of artifically-generated error sentences, does not post hits to mturk

generage_esl_hits.py -  generate ESL mturk hits, does not post hits to mturk

hit_dump_multi_test.py - pull all assignments from MTurk and dump raw values into csv file (hit_data_dump), for backup purposes

load_data_to_db.py - read sentences from file named in DATA_PATH (line 23) and add them to the esl_sentences data table, to be used for generating hits

mturk.py - methods for calling mturk api, using boto libraries

multi_test.py - pull all hits off of mturk and read into buffer_assignments table

process_qc.py - review control sentence for each submitted assignment, compute accuracy on that sentence, read and update worker-level statistics into esl_appr_buffer, determine whether assignment should be accepted or rejected, and enter accept/reject into esl_grades (does not do any actual accepting/rejected yet)

repost_hits.py - add assignments to HITs to replace assignments that were rejected for not meeting QC standards
 
------ LIBRARIES -------

controls.py - methods for pulling control sentences off of wikipedia, using the titles of the foreign language wikipedia pages (right now, only in urdu). 

edit_anal.py - methods for parsing edit data structures and organizing edits

edit_graph.py - definitions of edit, revision, and sentence objects, as well as graph data structures containing them

extract_data.py - functions for converting data in csv files into data structures defined in edit_graph, or other in-memory data structures 

figures.py - methods for generating graphs and figures for data analysis (not used here, included to make above scripts compile. planning to clean up code and remove this file from this repo soon...)	

generrors.py - methods to introduce random errors into English sentences

qc.py - methods for grading control sentences and paying workers based on performance

------ ORDER FOR RUNNING SCRIPTS -------

POST HITS:
sh reload_all.sh 
python generate_esl_hits.py (--reload if want to re-query for all control sentences)
python add_esl_hits_to_mturk.py 

RETRIEVE DATA:
python multitest.py
python buffer_update.py
python process_qc.py
(confirm approvals/rejections using apprej.log and DB tables)
python approve_reject.py 
python repost_hits.py


-


